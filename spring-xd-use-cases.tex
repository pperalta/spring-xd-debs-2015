\section{Use Cases}
The following customer use cases are being supported in the field by the Spring XD team.

\begin{itemize*}
\item \textbf{Fault Detection}: \textit{Challenge}: A large equipment manufacturer is  interested in ingesting machine data to apply predictive analytics to proactively monitor performance and adjust business operations. \textit{Solution}: Given the extensible architecture in Spring XD, a custom source module was created to handle proprietary data formats, thus allowing consumption and transformation of data complying with their proprietary standards. The predictive models, complying with PMML specification, were generated based on historical trends. Spring XD's analytic-pmml processor was used in a stream to intercept machine events to compute predictions in real-time. The outliers were captured in Redis for dashboard alerts and ad-hoc data analysis via REST.
\item \textbf{Enterprise Modernization}: \textit{Challenge}: A large retail provider is heavily invested in Hadoop ecosystem. They weren't keen on maintaining or supporting several products in production - operationalizing this was painful. They wanted to streamline and modernize their Hadoop workflows. \textit{Solution}: As one-stop runtime, Spring XD provides dozens of data integration adapters to send and receive data from external applications, thus allowing the customer to use the unified approach for all ingestion use-cases. Building upon Spring Batch, Spring XD also provides multiple batch jobs for data movements along with granular workflow steps. This further eliminated the need for relying on different workflow and data movement tools. Whether it is MapReduce, Hive, Pig, or HBase scripts - developer experience is the same.
\item \textbf{Data Ingest}: \textit{Challenge}: A startup in San Francisco was looking for a solution to unify stream and batch operations. \textit{Solution}: Spring XD is used as a standard tool for ingesting data into Hadoop. Whether it is real-time (i.e., online) or batch (i.e., offline), the out of the box fixtures delivered immediate benefits. Overall, the data integration, orchestration, and data movement capabilities were handled end to end by Spring XD.
\item \textbf{24/7 Production Pipelines}: \textit{Challenge}: A large IT enterprise wanted to build data pipelines to monitor current software and hardware sales in order to predict and forecast. Building pipelines in one; running them reliably 24/7 with strict SLAs is another big challenege. \textit{Solution}: Spring XD is built as highly-available runtime. Automatic recovery from fault sceanrios along with reproccessing of data events fulfilled SLAs guarantees. Production running pipelines in Spring XD are long-running processes. For ad-hoc operations such as querying, machine learning, or data crunching, `taps' in Spring XD were adopted to fork the data from primary pipeline. This results in no disruption with the primary pipeline, at the same time satisfying ad-hoc demands.
\item \textbf{Closed-loop Analytics}: \textit{Challenge}: A finance institution wanted to build a platform to detect fraudulent transactions. They had years of historical data in varying formats and the transactions happening in real-time at high volume. They wanted to automate generation of historical models from raw dataset and apply the models to real-time events. No in-house talent to build one; neither had budget to buy expensive products. \textit{Solution}: A batch job was used to learn from historical data thus producing predictive models complying with PMML specification. The last step in the batch workflow is orchestrated to deliver the generated models to streams that ingest for real-time predictions. The predictions were persisted in in-memory data grids to feed the dashboard. Spring XD, thus eliminating top-talent hires to operationalize analytics pipeline.
\end{itemize*}